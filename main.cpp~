#include <stdio.h>
#include <cv.h>
#include <highgui.h>
#include <iostream>
#include <string.h>
#include <math.h>
#include <vector>

using namespace std;
using namespace cv;

typedef struct Line {
	double nx;
	double ny;
	double d;
} Line;

void whitePixelExtraction(IplImage* frame, SparseMat sparseMat);
void getPixelAt(IplImage* img, int x, int y, int* rgb[3]);
void houghDetectLines(IplImage* src, IplImage* line_img);
double luminance(IplImage* image, int x, int y);
Mat calculateGradients(IplImage* src, IplImage* res, IplImage* wPixels);

const int THRESHOLD = 150;

#define PI 3.14159265

int main(int argc, char** argv) {
  
  const char* movie = "trimmed.avi";
  
  if(argc == 2) {
    movie = argv[1];
  }

  CvCapture* capture = cvCaptureFromAVI(movie);
  IplImage* image = 0;

  cvNamedWindow("After Gradient Removal", CV_WINDOW_AUTOSIZE);
  cvNamedWindow("White Pixels", CV_WINDOW_AUTOSIZE);
  cvNamedWindow("Hough", CV_WINDOW_AUTOSIZE);
  //Grabbing first frame
  image = cvQueryFrame(capture);
  if(!image) {
    cout << "Unable to parse video: " << movie << endl;
    return 0;
  }

  int mat_dims[2] = {image->height, image->width};
  SparseMat smat = SparseMat(2, mat_dims, CV_8UC1);
  whitePixelExtraction(image, smat);

  Mat m;
  smat.convertTo(m, CV_8UC1);
  IplImage i = m;
  cvShowImage("White Pixels", &i);

  IplImage* res;
  Mat grads = calculateGradients(&i,res, &i);  

  IplImage j = grads;
  cvShowImage("After Gradient Removal", &j);

  houghDetectLines(&j, NULL);

  while(true) {
    char key = cvWaitKey(30);
    if(key == 27)
      break;
  }
}

void houghDetectLines(IplImage* src, IplImage* l) {
  CvMemStorage* storage = cvCreateMemStorage(0);
  CvSeq* lines = 0;
  IplImage* color_dst = cvCreateImage(cvGetSize(src), 8, 3);
  IplImage* line_dst = cvCreateImage(cvGetSize(src), 8, 3);
  cvNamedWindow("lines", CV_WINDOW_AUTOSIZE);
  cvSet(line_dst, cvScalar(0,0,0));
  
  lines = cvHoughLines2(src, storage, CV_HOUGH_PROBABILISTIC, 
                        1, CV_PI/180,80,15,10);
  
  vector<Vec<double, 6> > vecs = vector<Vec<double,6> >();
  
//Only do at max 100 lines. Why more?!!
  cout << "Segs: " << lines->total << endl;
  for(int i = 0; i < MIN(lines->total, 100); i++) {
    
    CvPoint* lin = (CvPoint*)cvGetSeqElem(lines,i);
    
    double xdist = abs(lin[0].x-lin[1].x);
    double ydist = abs(lin[0].y-lin[1].y);
    double norm = sqrt(xdist*xdist + ydist*ydist);
    
    Vec<double, 6> v(lin[0].x, lin[0].y, lin[1].x, lin[1].y, xdist/norm, ydist/norm);
    vecs.push_back(v);

    cvLine(color_dst, lin[0], lin[1], CV_RGB(255,0,0),1,8);
    cvShowImage("After Gradient Removal", color_dst);
  }
  
  for(int j = 0; j < vecs.size(); j++) {
  
    CvPoint tt, ttt;
    tt.x = vecs[j][0];
    tt.y = vecs[j][1];
    ttt.x = vecs[j][2];
    ttt.y = vecs[j][3];
    cvLine(line_dst, tt, ttt, CV_RGB(0,255,255),1,8);
  
    double x_diff = abs(tt.x-ttt.x);
    double y_diff = abs(tt.y-ttt.y);
    int horizontal = 0;
  
    if(x_diff > y_diff)
      horizontal = 1;
    else
      horizontal = 0;
  
    for(int i = j+1; i < vecs.size()-1; i++) {
    
      double dprod = vecs[i][4]*vecs[j][4] + vecs[i][5]*vecs[j][5];
      double angle = acos(dprod);
    
      double pt1x = vecs[i][0];
      double pt1y = vecs[i][1];
      double pt2x = vecs[i][2];
      double pt2y = vecs[i][3];
    
      double pt3x = vecs[j][0];
      double pt3y = vecs[j][1];
      double pt4x = vecs[j][2];
      double pt4y = vecs[j][3];
    
      double d1 = sqrt( pow(pt1x-pt3x,2) + pow(pt1y-pt3y,2));
      double d2 = sqrt( pow(pt1x-pt4x,2) + pow(pt1y-pt4y,2));
      double d3 = sqrt( pow(pt2x-pt3x,2) + pow(pt2y-pt3y,2));
      double d4 = sqrt( pow(pt2x-pt4x,2) + pow(pt2y-pt4y,2));
    
      int close = 0;
      int distThresh = 3;
      if(horizontal)
        close = (abs(pt1y-pt3y) < distThresh) || (abs(pt1y-pt4y) < distThresh) || (abs(pt2y-pt3y) < distThresh) || (abs(pt2y-pt3y) < distThresh);
      else
        close = (abs(pt1x-pt3x) < distThresh) || (abs(pt1x-pt4x) < distThresh) || (abs(pt2x-pt3x) < distThresh) || (abs(pt2x-pt3x) < distThresh);
      
    
      if(angle < PI/4 && close){
        cout << "Parallel and close" << endl;
        CvPoint t1,t2;
        t1.x = vecs[i][0];
        t1.y = vecs[i][1];
        t2.x = vecs[i][2];
        t2.y = vecs[i][3];
        cvLine(line_dst, t1, t2, CV_RGB(0,0,255),1,8);
        vecs.erase(vecs.begin()+i);
        i--;
      }
    }
  }
  cout << "Num parallel " << vecs.size() << endl; 
  cvShowImage("lines", line_dst);
}

void whitePixelExtraction(IplImage* frame, SparseMat sparseMat) {
  sparseMat.clear();
  
  double thetal = 128;
  double thetad = 20;
  int dist = 3;
  
  for(int j = dist; j < frame->height-dist; j++) {
    for(int i = dist; i < frame->width-dist; i++) {
      double lum = luminance(frame, i, j);
      int value = 0;
      
      if(lum >= thetal && lum-luminance(frame, i-dist, j) > thetad && 
	 lum - luminance(frame,i+dist,j) > thetad) {
	value=1;
      }
      else if(lum >= thetal && lum-luminance(frame,i,j-dist) > thetad &&
	      lum-luminance(frame, i, j+dist) > thetad) {
	value=1;
      }
      else {
	value=0;
      }
      sparseMat.ref<uchar>(j,i) = value*255;
    }
  }
}

double luminance(IplImage* src, int j, int i) {
	int height = src->height;
	int width = src->width;
	int step = src->widthStep/sizeof(float);
	int channels = src->nChannels; 
	float* data = (float *)src->imageData;

	int red = ((uchar *)(src->imageData + i*src->widthStep))[j*src->nChannels + 2];
	int green = ((uchar *)(src->imageData + i*src->widthStep))[j*src->nChannels + 1];
	int blue = ((uchar *)(src->imageData + i*src->widthStep))[j*src->nChannels + 0];
	double res = sqrt(.241*red*red + .691*green*green + .068*blue*blue);
  return res;
}

Mat calculateGradients(IplImage* src, IplImage* res, IplImage* whitePixels) {
  IplImage* blur_src = cvCreateImage(cvGetSize(src), IPL_DEPTH_8U, 1);
  res = cvCreateImage(cvGetSize(src), IPL_DEPTH_32F, 1);
  cvSmooth(src,blur_src);
  //	cvSobel(blur_src, res, 1, 1); //Computes image gradients for x,y using 3x3 matrix
  
  //  Mat res_m = res;//(res); //Converts to Matrix
  
  //  Mat mul;
  //  gemm(res_m, res_m, 1, NULL, 0, mul, GEMM_2_T);
  
  Mat m(whitePixels);
  IplImage* lamdas = cvCreateImage(cvGetSize(src), IPL_DEPTH_32F, 6);
  cvCornerEigenValsAndVecs(src, lamdas, 3, 3);
  
  for(int i = 0; i < src->height; ++i) {
    for(int j = 0; j < src->width; ++j) {
      
      float whiteP = ((uchar *)(whitePixels->imageData + i*whitePixels->widthStep))[j*whitePixels->nChannels + 0];			
      
      if(whiteP == 255) {
				float l1 = ((uchar *)(lamdas->imageData + i*lamdas->widthStep))[j*lamdas->nChannels + 5];
				float l2 = ((uchar *)(lamdas->imageData + i*lamdas->widthStep))[j*lamdas->nChannels + 4];
				if(l2 != 0 && l1 >= 4*l2) {
	  			((uchar *)(whitePixels->imageData + i*whitePixels->widthStep))[j*whitePixels->nChannels + 0] = 0;
	  			m.at<int>(i,j) = 0;
	  
	  		//cout << "Old Value: " << whiteP << " New: " << m.at<int>(i,j) << endl;
				}
      }
      if(i < 50 || i > 300)
				m.at<int>(i,j) = 0;
    }
  }
  IplImage m_img = m;
  
  return m;//res_m;
}

void getPixelAt(IplImage* src, int i, int j, int* rgb[3]) {
  
	int height = src->height;
	int width = src->width;
	int step = src->widthStep/sizeof(float);
	int channels = src->nChannels; 
	float* data = (float *)src->imageData;
	
	int r = data[i*step+j*channels+2];
	int g = data[i*step+j*channels+1];
	int b = data[i*step+j*channels+0];
	*rgb[0] = b;
	*rgb[1] = g;
	*rgb[2] = r;
}
